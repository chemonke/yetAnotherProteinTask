{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "318e3bfe",
   "metadata": {},
   "source": [
    "Identification of the cysteines that bind the ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d9e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 15, 41]\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "record = SeqIO.read(\"./3iwl/rcsb_pdb_3IWL.fasta\", \"fasta\")\n",
    "cys_positions = [i+1 for i, aa in enumerate(str(record.seq)) if aa == \"C\"]\n",
    "print(cys_positions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470db6d",
   "metadata": {},
   "source": [
    "12, 15 are the relevant cysteines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8619c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf library/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6863de8",
   "metadata": {},
   "source": [
    "# Generation of mutated sequences\n",
    "\n",
    "Cysteine reactivity can be increased by the presence of charged groups close to them. We will create a set of mutated sequences where amino acids in a defined range around the cysteines at the 12 and 15 position are replaced by arginine and lysine.\n",
    "\n",
    "The code below allows you to create full or partial sets of mutated sequences based on what you choose in the `variants` variable.\n",
    "\n",
    "The output is a fasta file that contains the wild type, as well as all of the generated types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "755baf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 200,001 total sequences (WT + variants)\n",
      "Wrote 200,001 sequences → library/library.fasta.gz  (4.07 MB)\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations, product\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from pathlib import Path\n",
    "import random, gzip\n",
    "\n",
    "# ───────────────────────────  USER SETTINGS  ────────────────────────────\n",
    "fasta_in     = \"./3iwl/rcsb_pdb_3IWL.fasta\"\n",
    "design_range = range(5, 22)          # inclusive (5–21)\n",
    "catalytic    = {12, 15}              # MUST stay C\n",
    "variants     = \"random\"              # \"single\", \"double\", \"full\", \"random\"\n",
    "lib_size     = 200000                # only used for \"random\"\n",
    "library_path = Path(\"library/library.fasta.gz\")   # .gz → compressed, .fasta → plain\n",
    "# ────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "record  = SeqIO.read(fasta_in, \"fasta\")\n",
    "wt_seq  = str(record.seq)\n",
    "\n",
    "# positions we’re allowed to mutate\n",
    "positions = [p for p in design_range if p not in catalytic]\n",
    "choices   = {pos: (\"K\", \"R\") for pos in positions}\n",
    "\n",
    "# ── build mut_lists according to the library type ───────────────────────\n",
    "mut_lists = []\n",
    "\n",
    "if variants == \"single\":\n",
    "    mut_lists = [[(p, aa)] for p in positions for aa in choices[p]]\n",
    "\n",
    "elif variants == \"double\":\n",
    "    mut_lists = [[(p1, a1), (p2, a2)]\n",
    "                 for (p1, p2) in combinations(positions, 2)\n",
    "                 for (a1, a2) in product(choices[p1], choices[p2])]\n",
    "\n",
    "elif variants == \"full\":\n",
    "    per_site = [(*choices[p], None) for p in positions]          # None = keep WT\n",
    "    for aa_tuple in product(*per_site):\n",
    "        mut = [(p, aa) for p, aa in zip(positions, aa_tuple) if aa is not None]\n",
    "        if mut:                                                  # drop all-WT case\n",
    "            mut_lists.append(mut)\n",
    "\n",
    "elif variants == \"random\":\n",
    "    seen, rng = set(), random.Random(42)\n",
    "    while len(mut_lists) < lib_size:\n",
    "        k   = rng.randint(1, len(positions))                     # # sites to mutate\n",
    "        pos = rng.sample(positions, k)\n",
    "        mut = [(p, rng.choice(choices[p])) for p in pos]\n",
    "        sig = tuple(sorted(mut))\n",
    "        if sig not in seen:\n",
    "            seen.add(sig)\n",
    "            mut_lists.append(mut)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"variants must be one of: single, double, full, random\")\n",
    "\n",
    "# ── assemble SeqRecord objects ──────────────────────────────────────────\n",
    "base_id = record.id.split(\"|\", 1)[0]           # remove any upstream pipes\n",
    "records = []\n",
    "\n",
    "# optional: include wild-type first\n",
    "records.append(\n",
    "    SeqRecord(Seq(wt_seq),\n",
    "              id=\"WT|WT|WT\",         # three fields separated by “|”\n",
    "              description=\"wild-type\")\n",
    ")\n",
    "\n",
    "\n",
    "for i, muts in enumerate(mut_lists, 1):\n",
    "    seq_list = list(wt_seq)\n",
    "    tags     = []\n",
    "    for pos, aa in muts:\n",
    "        idx = pos - 1\n",
    "        tags.append(f\"{wt_seq[idx]}{pos}{aa}\")\n",
    "        seq_list[idx] = aa\n",
    "\n",
    "    var_seq  = \"\".join(seq_list)\n",
    "    tag_str  = \"-\".join(tags)\n",
    "    var_id   = f\"{base_id}|VAR{i:05d}|{tag_str}\"\n",
    "    records.append(SeqRecord(Seq(var_seq), id=var_id, description=\"\"))\n",
    "\n",
    "print(f\"Built {len(records):,} total sequences (WT + variants)\")\n",
    "\n",
    "# ── write them all at once ──────────────────────────────────────────────\n",
    "library_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if library_path.suffix == \".gz\":\n",
    "    with gzip.open(library_path, \"wt\") as handle:\n",
    "        SeqIO.write(records, handle, \"fasta\")\n",
    "else:\n",
    "    with library_path.open(\"wt\") as handle:\n",
    "        SeqIO.write(records, handle, \"fasta\")\n",
    "\n",
    "size_mb = library_path.stat().st_size / 1_000_000\n",
    "print(f\"Wrote {len(records):,} sequences → {library_path}  ({size_mb:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a97c4",
   "metadata": {},
   "source": [
    "[sbPCR](https://github.com/wendao/sbPCR) is a machine learning model that can predict the reactivity of cysteines based on just the sequence. The accompanying paper by Wang et al. can be found [here](https://pubs.acs.org/doi/10.1021/acs.biochem.7b00897).\n",
    "Please note that you need `libsvm` installed in order to use sbPCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd03f003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'sbPCR'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone https://github.com/wendao/sbPCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6db08",
   "metadata": {},
   "source": [
    "We clear the sbPCR_run directory from previous results and extract the contents of our sequence library. We then pass the sequences into sbPCR as outlined in the documentation. Please note that the \"Accuracy\" prediction in the output is an artifact of `libsmv`and has no bearing on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "391cd0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.2122% (529276/600003) (classification)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf sbPCR_run && mkdir sbPCR_run\n",
    "gunzip -c library/library.fasta.gz > library/library.fasta\n",
    "\n",
    "cd sbPCR_run\n",
    "python ../sbPCR/scripts/get_align.py  ../library/library.fasta\n",
    "python ../sbPCR/scripts/get_feature.py\n",
    "svm-predict  formated_input  ../sbPCR/models/train_v1.model  predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a8d3b",
   "metadata": {},
   "source": [
    "We can now extract the results from the sbPCR run. We calculate the number of sequences deemed reactive by sbPCR as a percentage of the whole set, and store it in `filtered_sequences.fasta`. On average, about 10% of sequences are deemed reactive by sbPCR. Notably, the original wild type is NOT deemed reactive. sbPCR judges reactivity based on empirical data, in which the top 10% most reactive samples received the label \"reactive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a28ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT reactive at both cysteines =  False\n",
      "20446/200001 = 10.22% variants have both Cys 12 and Cys 15 predicted reactive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20447"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, pathlib\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "wd = pathlib.Path(\"sbPCR_run\")\n",
    "\n",
    "# 1 ─ read sbPCR outputs (label only)\n",
    "align = pd.read_csv(\n",
    "    wd / \"align\",  sep=r\"\\s+\",  header=None,\n",
    "    names=[\"variant\", \"pos\", \"window\"]\n",
    ")\n",
    "pred  = pd.read_csv(\n",
    "    wd / \"predict\", sep=r\"\\s+\", header=None,\n",
    "    names=[\"label\"], dtype={\"label\": int}\n",
    ")\n",
    "\n",
    "data = pd.concat([align, pred], axis=1)\n",
    "\n",
    "# 2 ─ is WT reactive at both catalytic sites?\n",
    "wt_rows = data[data.variant.str.startswith(\"WT\") & data.pos.isin([12, 15])]\n",
    "wt_reactive = (len(wt_rows) == 2) and (wt_rows[\"label\"] == 1).all()\n",
    "print(\"WT reactive at both cysteines = \", wt_reactive)\n",
    "\n",
    "# 3 ─ variants with *both* sites reactive\n",
    "both_hits = (\n",
    "    data.query(\"pos in [12, 15] and label == 1\")\n",
    "        .groupby(\"variant\")\n",
    "        .size()\n",
    "        .loc[lambda s: s == 2]\n",
    "        .index\n",
    ")\n",
    "\n",
    "n_hits = len(both_hits)\n",
    "lib_size = data.variant.nunique()\n",
    "pct = n_hits / lib_size * 100\n",
    "\n",
    "print(f\"{n_hits}/{lib_size} = {pct:.2f}% variants have both Cys 12 and Cys 15 predicted reactive\")\n",
    "\n",
    "# 4 ─ Load full-length sequences and map VAR IDs\n",
    "\n",
    "# Load full sequences as dictionary: {full_id : SeqRecord}\n",
    "full_sequences = SeqIO.to_dict(SeqIO.parse(\"library/library.fasta\", \"fasta\"))\n",
    "\n",
    "# Build mapping: {VARxxxxx : SeqRecord}\n",
    "id_map = {}\n",
    "for full_id, record in full_sequences.items():\n",
    "    parts = full_id.split(\"|\")\n",
    "    if len(parts) >= 2:\n",
    "        var_id = parts[1]  # e.g. VAR00020\n",
    "        id_map[var_id] = record\n",
    "\n",
    "# 5 ─ Extract filtered variants\n",
    "filtered = data[data.variant.isin(both_hits)].drop_duplicates(\"variant\")\n",
    "\n",
    "# 6 ─ Build SeqRecords using full-length sequences\n",
    "\n",
    "# First, include the wild-type\n",
    "wt_record = None\n",
    "for full_id, record in full_sequences.items():\n",
    "    if full_id.startswith(\"WT|WT|WT\"):\n",
    "        wt_record = SeqRecord(record.seq, id=\"WT\", description=\"wild-type\")\n",
    "        break\n",
    "\n",
    "# Collect records: WT first, then variants\n",
    "records = []\n",
    "\n",
    "if wt_record:\n",
    "    records.append(wt_record)\n",
    "\n",
    "# Add variants\n",
    "records.extend([\n",
    "    SeqRecord(\n",
    "        id_map[row.variant].seq,\n",
    "        id=row.variant,\n",
    "        description=\"\"\n",
    "    )\n",
    "    for row in filtered.itertuples()\n",
    "])\n",
    "\n",
    "# 7 ─ Write full-length filtered sequences\n",
    "SeqIO.write(records, \"filtered_fastas/filtered_sequences.fasta\", \"fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f49f02b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote example_from_cif.pdb\n",
      "PROPKA finished\n",
      "\n",
      "Cysteine pKa values\n",
      "  CYS A  12: 8.34\n",
      "  CYS A  15: 9.83\n",
      "  CYS A  41: 9.41\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Minimal “CIF → PROPKA” workflow that prints one reliable pKa per\n",
    "titratable cysteine.\n",
    "\n",
    "Requirements\n",
    "------------\n",
    "  gemmi     (pip install gemmi)\n",
    "  propka3   (≥ 3.5; callable as `propka3`)\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import re\n",
    "import gemmi\n",
    "\n",
    "# ── USER SETTINGS ────────────────────────────────────────────\n",
    "cif_input      = 'alphafold/VAR00020.cif'           # mmCIF file\n",
    "pdb_output     = 'example_from_cif.pdb'         # temporary PDB\n",
    "propka_output  = pdb_output.replace('.pdb', '.pka')\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "\n",
    "# 1 ▸ CIF → PDB ------------------------------------------------------------\n",
    "doc = gemmi.cif.read_file(cif_input)\n",
    "gemmi.make_structure_from_block(doc.sole_block()).write_pdb(pdb_output)\n",
    "print(f'Wrote {pdb_output}')\n",
    "\n",
    "# 2 ▸ PROPKA ---------------------------------------------------------------\n",
    "subprocess.run(['propka3', pdb_output], check=True)\n",
    "if not Path(propka_output).is_file():\n",
    "    raise FileNotFoundError(f'PROPKA output {propka_output} not found')\n",
    "print('PROPKA finished')\n",
    "\n",
    "# 3 ▸ Extract one non-zero pKa per cysteine (header-independent) -----------\n",
    "cys_line = re.compile(\n",
    "    r'^\\s*(?:\\d+\\s+)?'       # optional leading index\n",
    "    r'CYS\\s+'                # residue name\n",
    "    r'(\\d+)\\s+'              # residue number           (group 1)\n",
    "    r'([A-Za-z0-9]?)\\s+'     # optional chain ID        (group 2)\n",
    "    r'([0-9]+\\.[0-9]+)'      # pKa value                (group 3)\n",
    ")\n",
    "\n",
    "cys_pka = {}\n",
    "with open(propka_output) as f:\n",
    "    for line in f:\n",
    "        m = cys_line.match(line)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        resnum, chain, pka_str = m.groups()\n",
    "        pka = float(pka_str)\n",
    "\n",
    "        # ignore “0.00 / 99.99” artefacts and keep first non-zero value\n",
    "        if 0.1 < pka < 99.0 and (chain, resnum) not in cys_pka:\n",
    "            cys_pka[(chain, resnum)] = pka\n",
    "\n",
    "# 4 ▸ Report ---------------------------------------------------------------\n",
    "if cys_pka:\n",
    "    print('\\nCysteine pKa values')\n",
    "    for (chain, resnum), pka in sorted(cys_pka.items()):\n",
    "        chain_display = chain if chain else '<no-ID>'\n",
    "        print(f'  CYS {chain_display}{resnum:>4}: {pka:.2f}')\n",
    "else:\n",
    "    print('\\nNo titratable cysteines reported (likely all in disulfide bonds)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3b76ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wild-type pKa values (3IWL)\n",
      "  CYS   12: 9.25\n",
      "  CYS   15: 6.71\n",
      "\n",
      "Summary statistics across all variants\n",
      "  CYS   12: mean = 8.79, sd = 0.64, n = 2\n",
      "  CYS   15: mean = 8.27, sd = 2.21, n = 2\n",
      "\n",
      "Top 10 variants by |ΔpKa| (largest site difference)\n",
      "  VAR00020                   CYS 12 8.34 (Δ-0.91); CYS 15 9.83 (Δ+3.12)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch “CIF → PROPKA” runner for the alphafold/ directory.\n",
    "Focuses on CYS 12 and CYS 15 only.\n",
    "\n",
    "Output\n",
    "------\n",
    "• Wild-type (3IWL) pKa values\n",
    "• Mean and s.d. for each site across all variants\n",
    "• Top-10 variants with the largest |ΔpKa| at either site\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import statistics as stats\n",
    "import tempfile\n",
    "import re\n",
    "import gemmi\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "# ────────────────────────── USER SETTINGS ──────────────────────────\n",
    "folder           = Path('alphafold')     # directory containing *.cif\n",
    "wild_type_file   = '3iwl.cif'            # case-exact filename\n",
    "propka_exe       = 'propka3'             # command in $PATH\n",
    "sites_of_interest = {12, 15}             # residue numbers\n",
    "# ───────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Regex that matches a normal PROPKA Cys line (with or without leading index)\n",
    "cys_line = re.compile(\n",
    "    r'^\\s*(?:\\d+\\s+)?'        # optional index\n",
    "    r'CYS\\s+'\n",
    "    r'(\\d+)\\s+'               # residue number   – group 1\n",
    "    r'([A-Za-z0-9]?)\\s+'      # chain ID (0–1 ch) – group 2\n",
    "    r'([0-9]+\\.[0-9]+)'       # pKa value         – group 3\n",
    ")\n",
    "\n",
    "def extract_cys_pka(pka_file: Path) -> dict[int, float]:\n",
    "    \"\"\"Return {resnum: pKa} for sites_of_interest in one PROPKA .pka file.\"\"\"\n",
    "    result: dict[int, float] = {}\n",
    "    with pka_file.open() as fh:\n",
    "        for line in fh:\n",
    "            m = cys_line.match(line)\n",
    "            if not m:\n",
    "                continue\n",
    "            resnum = int(m.group(1))\n",
    "            if resnum not in sites_of_interest:\n",
    "                continue\n",
    "            pka = float(m.group(3))\n",
    "            if 0.1 < pka < 99.0 and resnum not in result:  # first non-artefact wins\n",
    "                result[resnum] = pka\n",
    "    return result\n",
    "\n",
    "def run_one_cif(cif_path: Path, workdir: Path) -> dict[int, float]:\n",
    "    \"\"\"Convert CIF→PDB, run PROPKA in *workdir*, return pKa dict.\"\"\"\n",
    "    pdb_path = workdir / (cif_path.stem + '.pdb')\n",
    "    # CIF → PDB (Gemmi)\n",
    "    structure = gemmi.make_structure_from_block(\n",
    "        gemmi.cif.read_file(str(cif_path)).sole_block()\n",
    "    )\n",
    "    structure.write_pdb(str(pdb_path))\n",
    "\n",
    "    # PROPKA (run inside workdir so output lands there)\n",
    "    subprocess.run([propka_exe, pdb_path.name],\n",
    "                   cwd=workdir,\n",
    "                   stdout=subprocess.DEVNULL,\n",
    "                   stderr=subprocess.DEVNULL,\n",
    "                   check=True)\n",
    "\n",
    "    pka_file = pdb_path.with_suffix('.pka')\n",
    "    if not pka_file.is_file():\n",
    "        raise FileNotFoundError(f'Expected {pka_file} not written by PROPKA')\n",
    "\n",
    "    return extract_cys_pka(pka_file)\n",
    "\n",
    "# ────────────────────────── MAIN WORK ─────────────────────────────\n",
    "if not folder.is_dir():\n",
    "    sys.exit(f'Error: directory {folder} does not exist')\n",
    "\n",
    "records: dict[str, dict[int, float]] = {}   # {variant_name: {resnum: pKa}}\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    workdir = Path(tmp)\n",
    "\n",
    "    for cif in sorted(folder.glob('*.cif')):\n",
    "        try:\n",
    "            pka_dict = run_one_cif(cif, workdir)\n",
    "            if pka_dict:            # store only if at least one site was found\n",
    "                records[cif.stem] = pka_dict\n",
    "        except Exception as exc:\n",
    "            print(f'[WARN] {cif.name}: {exc}', file=sys.stderr)\n",
    "\n",
    "# ensure wild-type is present\n",
    "wt_name = Path(wild_type_file).stem\n",
    "if wt_name not in records:\n",
    "    sys.exit(f'Wild-type file {wild_type_file} did not yield data – aborting.')\n",
    "\n",
    "wt = records[wt_name]\n",
    "\n",
    "# ────────────────────────── STATISTICS ────────────────────────────\n",
    "stats_summary = {site: [] for site in sites_of_interest}\n",
    "for rec in records.values():\n",
    "    for site in sites_of_interest:\n",
    "        if site in rec:\n",
    "            stats_summary[site].append(rec[site])\n",
    "\n",
    "# rank variants by maximum |ΔpKa| at the two sites\n",
    "ranked: list[tuple[float, str, dict[int, float]]] = []\n",
    "for name, rec in records.items():\n",
    "    if name == wt_name:\n",
    "        continue\n",
    "    delta = max(\n",
    "        abs(rec.get(site, wt[site]) - wt[site])\n",
    "        for site in sites_of_interest\n",
    "        if site in wt\n",
    "    )\n",
    "    ranked.append((delta, name, rec))\n",
    "\n",
    "ranked.sort(reverse=True)\n",
    "top10 = ranked[:10]\n",
    "\n",
    "# ────────────────────────── REPORT ───────────────────────────────\n",
    "print('\\nWild-type pKa values (3IWL)')\n",
    "for site in sorted(sites_of_interest):\n",
    "    if site in wt:\n",
    "        print(f'  CYS {site:>4}: {wt[site]:.2f}')\n",
    "    else:\n",
    "        print(f'  CYS {site:>4}: not titratable (disulfide)')\n",
    "\n",
    "print('\\nSummary statistics across all variants')\n",
    "for site in sorted(sites_of_interest):\n",
    "    values = stats_summary[site]\n",
    "    if values:\n",
    "        mean = stats.mean(values)\n",
    "        sd   = stats.stdev(values) if len(values) > 1 else 0.0\n",
    "        print(f'  CYS {site:>4}: mean = {mean:.2f}, sd = {sd:.2f}, n = {len(values)}')\n",
    "    else:\n",
    "        print(f'  CYS {site:>4}: no data')\n",
    "\n",
    "print('\\nTop 10 variants by |ΔpKa| (largest site difference)')\n",
    "for delta, name, rec in top10:\n",
    "    parts = []\n",
    "    for site in sorted(sites_of_interest):\n",
    "        if site in rec and site in wt:\n",
    "            diff = rec[site] - wt[site]\n",
    "            parts.append(f'CYS {site} {rec[site]:.2f} (Δ{diff:+.2f})')\n",
    "    print(f'  {name:25}  {\"; \".join(parts)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
