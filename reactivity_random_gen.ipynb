{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c1dd63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "df = pd.read_csv('Real_mutated_seqs.csv')\n",
    "\n",
    "with gzip.open('library/library.fasta.gz', 'wt') as fasta_file:\n",
    "    for idx, row in df.iterrows():\n",
    "        fasta_file.write(f\">seq{idx+1}|GENE{idx+1}|source\\n\")\n",
    "        fasta_file.write(f\"{row['Sequence']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a97c4",
   "metadata": {},
   "source": [
    "[sbPCR](https://github.com/wendao/sbPCR) is a machine learning model that can predict the reactivity of cysteines based on just the sequence. The accompanying paper by Wang et al. can be found [here](https://pubs.acs.org/doi/10.1021/acs.biochem.7b00897).\n",
    "Please note that you need `libsvm` installed in order to use sbPCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd03f003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'sbPCR'...\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git clone https://github.com/wendao/sbPCR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6db08",
   "metadata": {},
   "source": [
    "We clear the sbPCR_run directory from previous results and extract the contents of our sequence library. We then pass the sequences into sbPCR as outlined in the documentation. Please note that the \"Accuracy\" prediction in the output is an artifact of `libsmv`and has no bearing on this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "391cd0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 96.9697% (64/66) (classification)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf sbPCR_run && mkdir sbPCR_run\n",
    "gunzip -c library/library.fasta.gz > library/library.fasta\n",
    "\n",
    "cd sbPCR_run\n",
    "python ../sbPCR/scripts/get_align.py  ../library/library.fasta\n",
    "python ../sbPCR/scripts/get_feature.py\n",
    "svm-predict  formated_input  ../sbPCR/models/train_v1.model  predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a8d3b",
   "metadata": {},
   "source": [
    "We can now extract the results from the sbPCR run. We calculate the number of sequences deemed reactive by sbPCR as a percentage of the whole set, and store it in `filtered_sequences.fasta`. On average, about 10% of sequences are deemed reactive by sbPCR. Notably, the original wild type is NOT deemed reactive. sbPCR judges reactivity based on empirical data, in which the top 10% most reactive samples received the label \"reactive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55a28ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT reactive at both cysteines =  False\n",
      "0/21 = 0.00% variants have both Cys 12 and Cys 15 predicted reactive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, pathlib\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "wd = pathlib.Path(\"sbPCR_run\")\n",
    "\n",
    "# 1 ─ read sbPCR outputs (label only)\n",
    "align = pd.read_csv(\n",
    "    wd / \"align\",  sep=r\"\\s+\",  header=None,\n",
    "    names=[\"variant\", \"pos\", \"window\"]\n",
    ")\n",
    "pred  = pd.read_csv(\n",
    "    wd / \"predict\", sep=r\"\\s+\", header=None,\n",
    "    names=[\"label\"], dtype={\"label\": int}\n",
    ")\n",
    "\n",
    "data = pd.concat([align, pred], axis=1)\n",
    "\n",
    "# 2 ─ is WT reactive at both catalytic sites?\n",
    "wt_rows = data[data.variant.str.startswith(\"WT\") & data.pos.isin([12, 15])]\n",
    "wt_reactive = (len(wt_rows) == 2) and (wt_rows[\"label\"] == 1).all()\n",
    "print(\"WT reactive at both cysteines = \", wt_reactive)\n",
    "\n",
    "# 3 ─ variants with *both* sites reactive\n",
    "both_hits = (\n",
    "    data.query(\"pos in [12, 15] and label == 1\")\n",
    "        .groupby(\"variant\")\n",
    "        .size()\n",
    "        .loc[lambda s: s == 2]\n",
    "        .index\n",
    ")\n",
    "\n",
    "n_hits = len(both_hits)\n",
    "lib_size = data.variant.nunique()\n",
    "pct = n_hits / lib_size * 100\n",
    "\n",
    "print(f\"{n_hits}/{lib_size} = {pct:.2f}% variants have both Cys 12 and Cys 15 predicted reactive\")\n",
    "\n",
    "# 4 ─ Load full-length sequences and map VAR IDs\n",
    "\n",
    "# Load full sequences as dictionary: {full_id : SeqRecord}\n",
    "full_sequences = SeqIO.to_dict(SeqIO.parse(\"library/library.fasta\", \"fasta\"))\n",
    "\n",
    "# Build mapping: {VARxxxxx : SeqRecord}\n",
    "id_map = {}\n",
    "for full_id, record in full_sequences.items():\n",
    "    parts = full_id.split(\"|\")\n",
    "    if len(parts) >= 2:\n",
    "        var_id = parts[1]  # e.g. VAR00020\n",
    "        id_map[var_id] = record\n",
    "\n",
    "# 5 ─ Extract filtered variants\n",
    "filtered = data[data.variant.isin(both_hits)].drop_duplicates(\"variant\")\n",
    "\n",
    "# 6 ─ Build SeqRecords using full-length sequences\n",
    "\n",
    "# First, include the wild-type\n",
    "wt_record = None\n",
    "for full_id, record in full_sequences.items():\n",
    "    if full_id.startswith(\"WT|WT|WT\"):\n",
    "        wt_record = SeqRecord(record.seq, id=\"WT\", description=\"wild-type\")\n",
    "        break\n",
    "\n",
    "# Collect records: WT first, then variants\n",
    "records = []\n",
    "\n",
    "if wt_record:\n",
    "    records.append(wt_record)\n",
    "\n",
    "# Add variants\n",
    "records.extend([\n",
    "    SeqRecord(\n",
    "        id_map[row.variant].seq,\n",
    "        id=row.variant,\n",
    "        description=\"\"\n",
    "    )\n",
    "    for row in filtered.itertuples()\n",
    "])\n",
    "\n",
    "# 7 ─ Write full-length filtered sequences\n",
    "SeqIO.write(records, \"filtered_fastas/filtered_sequences.fasta\", \"fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b76ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wild-type pKa values (3IWL)\n",
      "  CYS   12: 9.25\n",
      "  CYS   15: 6.71\n",
      "\n",
      "Summary statistics across all variants\n",
      "  CYS   12: mean = 9.04, sd = 0.70, n = 21\n",
      "  CYS   15: mean = 7.00, sd = 1.34, n = 20\n",
      "\n",
      "Top 10 variants by |ΔpKa| (largest site difference)\n",
      "  fold_fold_job_19_model_0   CYS 12 7.64 (Δ-1.61); CYS 15 10.08 (Δ+3.37)\n",
      "  fold_1_model_0             CYS 12 7.53 (Δ-1.72); CYS 15 10.07 (Δ+3.36)\n",
      "  fold_2_model_0             CYS 12 7.75 (Δ-1.50); CYS 15 9.77 (Δ+3.06)\n",
      "  fold_fold_job_20_model_0   CYS 12 8.32 (Δ-0.93)\n",
      "  fold_fold_job_21_model_0   CYS 12 8.37 (Δ-0.88)\n",
      "  fold_5_model_0             CYS 12 9.19 (Δ-0.06); CYS 15 5.83 (Δ-0.88)\n",
      "  fold_fold_job_11_model_0   CYS 12 9.42 (Δ+0.17); CYS 15 5.99 (Δ-0.72)\n",
      "  fold_fold_job_15_model_0   CYS 12 9.25 (Δ+0.00); CYS 15 6.00 (Δ-0.71)\n",
      "  fold_fold_job_13_model_0   CYS 12 9.66 (Δ+0.41); CYS 15 6.05 (Δ-0.66)\n",
      "  fold_8_model_0             CYS 12 9.17 (Δ-0.08); CYS 15 6.05 (Δ-0.66)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Batch “CIF → PROPKA” runner for the alphafold/ directory.\n",
    "Focuses on CYS 12 and CYS 15 only.\n",
    "\n",
    "Output\n",
    "------\n",
    "• Wild-type (3IWL) pKa values\n",
    "• Mean and s.d. for each site across all variants\n",
    "• Top-10 variants with the largest |ΔpKa| at either site\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import statistics as stats\n",
    "import tempfile\n",
    "import re\n",
    "import gemmi\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "# ────────────────────────── USER SETTINGS ──────────────────────────\n",
    "folder           = Path('alphafold')     # directory containing *.cif\n",
    "wild_type_file   = '3iwl.cif'            # case-exact filename\n",
    "propka_exe       = 'propka3'             # command in $PATH\n",
    "sites_of_interest = {12, 15}             # residue numbers\n",
    "# ───────────────────────────────────────────────────────────────────\n",
    "\n",
    "# Regex that matches a normal PROPKA Cys line (with or without leading index)\n",
    "cys_line = re.compile(\n",
    "    r'^\\s*(?:\\d+\\s+)?'        # optional index\n",
    "    r'CYS\\s+'\n",
    "    r'(\\d+)\\s+'               # residue number   – group 1\n",
    "    r'([A-Za-z0-9]?)\\s+'      # chain ID (0–1 ch) – group 2\n",
    "    r'([0-9]+\\.[0-9]+)'       # pKa value         – group 3\n",
    ")\n",
    "\n",
    "def extract_cys_pka(pka_file: Path) -> dict[int, float]:\n",
    "    \"\"\"Return {resnum: pKa} for sites_of_interest in one PROPKA .pka file.\"\"\"\n",
    "    result: dict[int, float] = {}\n",
    "    with pka_file.open() as fh:\n",
    "        for line in fh:\n",
    "            m = cys_line.match(line)\n",
    "            if not m:\n",
    "                continue\n",
    "            resnum = int(m.group(1))\n",
    "            if resnum not in sites_of_interest:\n",
    "                continue\n",
    "            pka = float(m.group(3))\n",
    "            if 0.1 < pka < 99.0 and resnum not in result:  # first non-artefact wins\n",
    "                result[resnum] = pka\n",
    "    return result\n",
    "\n",
    "def run_one_cif(cif_path: Path, workdir: Path) -> dict[int, float]:\n",
    "    \"\"\"Convert CIF→PDB, run PROPKA in *workdir*, return pKa dict.\"\"\"\n",
    "    pdb_path = workdir / (cif_path.stem + '.pdb')\n",
    "    # CIF → PDB (Gemmi)\n",
    "    structure = gemmi.make_structure_from_block(\n",
    "        gemmi.cif.read_file(str(cif_path)).sole_block()\n",
    "    )\n",
    "    structure.write_pdb(str(pdb_path))\n",
    "\n",
    "    # PROPKA (run inside workdir so output lands there)\n",
    "    subprocess.run([propka_exe, pdb_path.name],\n",
    "                   cwd=workdir,\n",
    "                   stdout=subprocess.DEVNULL,\n",
    "                   stderr=subprocess.DEVNULL,\n",
    "                   check=True)\n",
    "\n",
    "    pka_file = pdb_path.with_suffix('.pka')\n",
    "    if not pka_file.is_file():\n",
    "        raise FileNotFoundError(f'Expected {pka_file} not written by PROPKA')\n",
    "\n",
    "    return extract_cys_pka(pka_file)\n",
    "\n",
    "# ────────────────────────── MAIN WORK ─────────────────────────────\n",
    "if not folder.is_dir():\n",
    "    sys.exit(f'Error: directory {folder} does not exist')\n",
    "\n",
    "records: dict[str, dict[int, float]] = {}   # {variant_name: {resnum: pKa}}\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    workdir = Path(tmp)\n",
    "\n",
    "    for cif in sorted(folder.glob('*.cif')):\n",
    "        try:\n",
    "            pka_dict = run_one_cif(cif, workdir)\n",
    "            if pka_dict:            # store only if at least one site was found\n",
    "                records[cif.stem] = pka_dict\n",
    "        except Exception as exc:\n",
    "            print(f'[WARN] {cif.name}: {exc}', file=sys.stderr)\n",
    "\n",
    "# ensure wild-type is present\n",
    "wt_name = Path(wild_type_file).stem\n",
    "if wt_name not in records:\n",
    "    sys.exit(f'Wild-type file {wild_type_file} did not yield data – aborting.')\n",
    "\n",
    "wt = records[wt_name]\n",
    "\n",
    "# ────────────────────────── STATISTICS ────────────────────────────\n",
    "stats_summary = {site: [] for site in sites_of_interest}\n",
    "for rec in records.values():\n",
    "    for site in sites_of_interest:\n",
    "        if site in rec:\n",
    "            stats_summary[site].append(rec[site])\n",
    "\n",
    "# rank variants by maximum |ΔpKa| at the two sites\n",
    "ranked: list[tuple[float, str, dict[int, float]]] = []\n",
    "for name, rec in records.items():\n",
    "    if name == wt_name:\n",
    "        continue\n",
    "    delta = max(\n",
    "        abs(rec.get(site, wt[site]) - wt[site])\n",
    "        for site in sites_of_interest\n",
    "        if site in wt\n",
    "    )\n",
    "    ranked.append((delta, name, rec))\n",
    "\n",
    "ranked.sort(reverse=True)\n",
    "top10 = ranked[:10]\n",
    "\n",
    "# ────────────────────────── REPORT ───────────────────────────────\n",
    "print('\\nWild-type pKa values (3IWL)')\n",
    "for site in sorted(sites_of_interest):\n",
    "    if site in wt:\n",
    "        print(f'  CYS {site:>4}: {wt[site]:.2f}')\n",
    "    else:\n",
    "        print(f'  CYS {site:>4}: not titratable (disulfide)')\n",
    "\n",
    "print('\\nSummary statistics across all variants')\n",
    "for site in sorted(sites_of_interest):\n",
    "    values = stats_summary[site]\n",
    "    if values:\n",
    "        mean = stats.mean(values)\n",
    "        sd   = stats.stdev(values) if len(values) > 1 else 0.0\n",
    "        print(f'  CYS {site:>4}: mean = {mean:.2f}, sd = {sd:.2f}, n = {len(values)}')\n",
    "    else:\n",
    "        print(f'  CYS {site:>4}: no data')\n",
    "\n",
    "print('\\nTop 10 variants by |ΔpKa| (largest site difference)')\n",
    "for delta, name, rec in top10:\n",
    "    parts = []\n",
    "    for site in sorted(sites_of_interest):\n",
    "        if site in rec and site in wt:\n",
    "            diff = rec[site] - wt[site]\n",
    "            parts.append(f'CYS {site} {rec[site]:.2f} (Δ{diff:+.2f})')\n",
    "    print(f'  {name:25}  {\"; \".join(parts)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
